{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5CfEpMZMqQEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, input_chars, target_chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.input_chars = sorted(input_chars)\n",
        "        self.input_char_indices = dict((c, i) for i, c in enumerate(self.input_chars))\n",
        "        self.input_indices_char = dict((i, c) for i, c in enumerate(self.input_chars))\n",
        "        self.target_chars = sorted(target_chars)\n",
        "        self.target_char_indices = dict((c, i) for i, c in enumerate(self.target_chars))\n",
        "        self.target_indices_char = dict((i, c) for i, c in enumerate(self.target_chars))\n",
        "\n",
        "        \n",
        "        print('Number of unique input tokens:', len(self.input_chars))\n",
        "        print('Number of unique output tokens:', len(self.target_chars))\n",
        "        \n",
        "    def encode_input(self, sequences, max_seq_length):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "#         print(\"input char indices\")\n",
        "#         print(self.input_char_indices)\n",
        "#         print(\"target char indices\")\n",
        "#         print(self.input_indices_char)\n",
        "        encoded_data = np.zeros(\n",
        "            (len(sequences), max_seq_length, len(self.input_chars)),\n",
        "            dtype='bool_')\n",
        "        for i, seq in enumerate(sequences):\n",
        "          for t, char in enumerate(seq):\n",
        "#               print(\"char: {0} at index: {1}\".format(char, self.input_char_indices[char]))\n",
        "              encoded_data[i, t, self.input_char_indices[char]] = 1.\n",
        "#               print(\"line nr {0}\".format(t))\n",
        "#               print(encoded_data[i, t])\n",
        "        return encoded_data\n",
        "      \n",
        "    def encode_target(self, sequences, max_seq_length):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        decoder_input_data = np.zeros((len(sequences), max_seq_length, len(self.target_chars)),\n",
        "        dtype='bool_')\n",
        "        decoder_target_data = np.zeros(\n",
        "            (len(sequences), max_seq_length, len(self.target_chars)),\n",
        "            dtype='bool_')\n",
        "        for i, seq in enumerate(sequences):\n",
        "          for t, char in enumerate(seq):\n",
        "            decoder_input_data[i, t, self.target_char_indices[char]] = 1.\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, self.target_char_indices[char]] = 1.\n",
        "\n",
        "        return decoder_input_data, decoder_target_data\n",
        "      \n",
        "    def decode_sequence(self, seq):\n",
        "      \n",
        "      # Encode the input as state vectors.\n",
        "      states_value = encoder_model.predict(seq)\n",
        "  \n",
        "      \n",
        "      \n",
        "      \n",
        "      # Generate empty target sequence of length 1.\n",
        "      target_seq = np.zeros((1, 1, len(self.target_chars)))\n",
        "      # Populate the first character of target sequence with the start character.\n",
        "      target_seq[0, 0, self.target_char_indices['\\t']] = 1.\n",
        "\n",
        "      \n",
        "      # Sampling loop for a batch of sequences\n",
        "      # (to simplify, here we assume a batch of size 1).\n",
        "      stop_condition = False\n",
        "      decoded_sentence = ''\n",
        "      while not stop_condition:\n",
        "          output_tokens, h, c = decoder_model.predict(\n",
        "              [target_seq] + states_value)\n",
        "\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_char = self.target_indices_char[sampled_token_index]\n",
        "          decoded_sentence += sampled_char\n",
        "\n",
        "          if (sampled_char == '\\n' or\n",
        "                  len(decoded_sentence) > max_decoder_seq_length):\n",
        "              stop_condition = True\n",
        "\n",
        "          target_seq = np.zeros((1, 1, len(self.target_chars)))\n",
        "          target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "#           print(\"Target seq\")\n",
        "#           print(target_seq)\n",
        "          \n",
        "          # Update states\n",
        "          states_value = [h, c]\n",
        " \n",
        "          \n",
        "      return decoded_sentence\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MNopJfA62Kyb",
        "colab_type": "code",
        "outputId": "895d6e37-0e4f-429b-dfb5-ba7a2fe3a0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "from pickle import load\n",
        "\n",
        "stories = load(open('/review_dataset.pkl', 'rb'))\n",
        "stories = stories[:10000]\n",
        "\n",
        "# Vectorize the data.\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "max_encoder_seq_length = 0\n",
        "max_decoder_seq_length = 0\n",
        "input_texts=[]\n",
        "target=[]\n",
        "for story in stories:\n",
        "    input_text = story['story']\n",
        "    \n",
        "    if len(input_text) > max_encoder_seq_length:\n",
        "      max_encoder_seq_length = len(input_text)\n",
        "   \n",
        "    target_text = story['highlights']\n",
        "\n",
        "    #\"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target.append(target_text)\n",
        "    if len(target_text) > max_decoder_seq_length:\n",
        "      max_decoder_seq_length = len(target_text)\n",
        "    \n",
        "    \n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "\n",
        "# print('Number of samples:', len(input_texts))\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "ctable = CharacterTable(input_characters, target_characters)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Stories 27782\n",
            "Max sequence length for inputs: 5437\n",
            "Max sequence length for outputs: 131\n",
            "Number of unique input tokens: 51\n",
            "Number of unique output tokens: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ccsd6uDR4ytF",
        "colab_type": "code",
        "outputId": "5129156a-b30c-465a-899e-ecb284dc6254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data = ctable.encode_input(input_texts, max_encoder_seq_length)\n",
        "decoder_input_data, decoder_target_data = ctable.encode_target(target, max_decoder_seq_length)\n",
        "\n",
        "\n",
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)\n",
        "print(decoder_target_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 5437, 51)\n",
            "(10000, 131, 46)\n",
            "(10000, 131, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CBqiAAnVvKLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_models(n_input, n_output, n_units):\n",
        "  # define training encoder\n",
        "  encoder_inputs = Input(shape=(None, n_input))\n",
        "  encoder = LSTM(n_units, return_state=True)\n",
        "  encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "  encoder_states = [state_h, state_c]\n",
        "  \n",
        "  # define training decoder\n",
        "  decoder_inputs = Input(shape=(None, n_output))\n",
        "  decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "  decoder_dense = Dense(n_output, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  \n",
        "  # define inference encoder\n",
        "  encoder_model = Model(encoder_inputs, encoder_states)\n",
        "  \n",
        "  # define inference decoder\n",
        "  decoder_state_input_h = Input(shape=(n_units,))\n",
        "  decoder_state_input_c = Input(shape=(n_units,))\n",
        "  decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "  decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs,  initial_state=decoder_states_inputs)\n",
        "  decoder_states = [state_h, state_c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "  \n",
        "  # return all models\n",
        "  return model, encoder_model, decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "suZeVqFmwoY4",
        "colab_type": "code",
        "outputId": "043b7d5d-0b41-4fda-ac57-d74ccdd77573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 30 # Number of epochs to train for.\n",
        "latent_dim = 256  # encoding space.\n",
        "\n",
        "\n",
        "model, encoder_model, decoder_model = define_models(len(ctable.input_chars), len(ctable.target_chars), latent_dim)\n",
        "print(\"Model summary\")\n",
        "model.summary()\n",
        "\n",
        "print(\"Encoder summary\")\n",
        "encoder_model.summary()\n",
        "\n",
        "\n",
        "print(\"Decoder summary\")\n",
        "decoder_model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "batch_size=batch_size,\n",
        "epochs=epochs,\n",
        "validation_split=0.2)\n",
        "Save model\n",
        "model.save('/home/model2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model summary\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_69 (InputLayer)           (None, None, 51)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_70 (InputLayer)           (None, None, 46)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_35 (LSTM)                  [(None, 256), (None, 315392      input_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_36 (LSTM)                  [(None, None, 256),  310272      input_70[0][0]                   \n",
            "                                                                 lstm_35[0][1]                    \n",
            "                                                                 lstm_35[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, None, 46)     11822       lstm_36[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 637,486\n",
            "Trainable params: 637,486\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Encoder summary\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_69 (InputLayer)        (None, None, 51)          0         \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               [(None, 256), (None, 256) 315392    \n",
            "=================================================================\n",
            "Total params: 315,392\n",
            "Trainable params: 315,392\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Decoder summary\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_70 (InputLayer)           (None, None, 46)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_71 (InputLayer)           (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_72 (InputLayer)           (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_36 (LSTM)                  [(None, None, 256),  310272      input_70[0][0]                   \n",
            "                                                                 input_71[0][0]                   \n",
            "                                                                 input_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, None, 46)     11822       lstm_36[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 322,094\n",
            "Trainable params: 322,094\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8XgnWfxCxkeL",
        "colab_type": "code",
        "outputId": "b7953b07-1407-4167-c0fd-103274e408a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "for seq_index in range(10):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = ctable.decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: got wild hair taffy ordered five pound bag taffy enjoyable many flavors watermelon root beer melon peppermint grape etc complaint bit much red black licorice flavored pieces particular favorites kids husband lasted two weeks would recommend brand taffy delightful treat\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: saltwater taffy great flavors soft chewy candy individually wrapped well none candies stuck together happen expensive version fralinger would highly recommend candy served beach themed party everyone loved\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: taffy good soft chewy flavors amazing would definitely recommend buying satisfying\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: right mostly sprouting cats eat grass love rotate around wheatgrass rye\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "-\n",
            "Input sentence: healthy dog food good digestion also good small puppies dog eats required amount every feeding\n",
            "Decoded sentence: great  ood an  ore the the the the the the the the the the the the the the the the the the the the the the the the the the the the t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}